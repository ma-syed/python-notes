{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Important Commands and Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizing Code Performance On Large Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cProfile\n",
    "# Usage Example\n",
    "profile_string = \"home_runs = calculate_runs(teams)\"\n",
    "cProfile.run(profile_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parallel Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful Library to create pools of threads and processes\n",
    "import concurrent.futures\n",
    "\n",
    "pool_thread = concurrent.futures.ThreadPoolExecutor(max_workers = 5)\n",
    "result = list(pool.map(function, args=(,)))\n",
    "\n",
    "pool_process = concurrent.futures.ProcessPoolExecutor(max_workers = 5)\n",
    "result = list(pool.map(function, args=(,)))\n",
    "\n",
    "# Threading Library\n",
    "import threading\n",
    "thread = threading.Thread(target=func, args=(team,)) # CREATE A THREAD based on a function\n",
    "thread.start() # START A THREAD\n",
    "thread.join() # WAIT FOR THE THREAD TO FINISH\n",
    "lock = threading.Lock() # CREATE A LOCK\n",
    "lock.acquire() # USE/Acquire the lock - use inside a function/method before using shared resource\n",
    "lock.release() # Release the lock - release after using shared resource\n",
    "\n",
    "# Multiprocessing Library\n",
    "import multiprocessing\n",
    "process = multiprocessing.Process(target=function, args=(email,))\n",
    "process.start()\n",
    "process.join()\n",
    "multiprocessing.Lock() # for shared resource eg stdout or DB\n",
    "\n",
    "# InterProcess Communication  Using Pipe objects\n",
    "parent_conn, child_conn = multiprocessing.Pipe()\n",
    "child_conn.send(data) # child_conn can be kept as an argument of the target function\n",
    "child_conn.close() # close connection\n",
    "data = parent_conn.recv() # receive data sent by child connection\n",
    "\n",
    "# Creating pool of processes to automatically take care of the interprocess communication\n",
    "from multiprocessing import Pool\n",
    "P = Pool(2) # pool of 2 workers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flushing stdout\n",
    "sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# equivalent of ls\n",
    "os.listdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a counter library\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regular expressions library\n",
    "import re\n",
    "re.sub(\"\\W+\", \" \", my_string) # '\\W+' = non-alphanumeric characters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example Code\n",
    "import concurrent.futures\n",
    "from collections import Counter\n",
    "import os\n",
    "import re\n",
    "\n",
    "def word_frequencies(filename):\n",
    "    with open(filename) as f:\n",
    "        data = f.read().lower()\n",
    "    data = re.sub(\"\\W+\", \" \", data) \n",
    "    words = data.split(\" \")\n",
    "    words = [w for w in words if len(w) >= 5]\n",
    "    count = Counter(words)\n",
    "    return dict(count)\n",
    "\n",
    "results = []\n",
    "pool = concurrent.futures.ProcessPoolExecutor(max_workers=2)\n",
    "filenames = [\"lines/{}\".format(f) for f in os.listdir(\"lines\")]\n",
    "word_counts = pool.map(word_frequencies, filenames)\n",
    "word_counts = list(word_counts)\n",
    "\n",
    "total_word_counts = {}\n",
    "\n",
    "for wc in word_counts:\n",
    "    for k,v in wc.items():\n",
    "        if k not in total_word_counts:\n",
    "            total_word_counts[k] = 0\n",
    "        total_word_counts[k] += v\n",
    "\n",
    "top_200 = Counter(total_word_counts).most_common(200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# initializing a df\n",
    "df = pd.DataFrame(data=[[1,2,3] for _ in range(3)], index='a b c'.split(), columns='d e f'.split())\n",
    "df.shape # rows,columns\n",
    "df.head(rows)\n",
    "df.tail(rows)\n",
    "df.iloc[1::2,:3] #integer based location\n",
    "df.loc['a','d'] # selects one element\n",
    "df.loc['a'] # selects entire row 'a'\n",
    "df['e'] # selects entire column 'e'\n",
    "df = pd.read_csv()\n",
    "df.reset_index(inplace = True) # will not save changes to the variable by default so we set param to true\n",
    "\n",
    "# bool masks\n",
    "df[(df['e'] > 1) & (df['d'] < 5)]\n",
    "\n",
    "# Value Counts\n",
    "vc = df.value_count()\n",
    "vc.to_dict() # converts to dictionary\n",
    "\n",
    "# aggregates\n",
    "df.max() # .min(), .sum(), .mean()\n",
    "\n",
    "# memory usage\n",
    "df.info(memory_usage = 'deep')\n",
    "df.memory_usage(deep=True)\n",
    "\n",
    "# Selecting dtype columns\n",
    "df.select_dtype(include = ['object','float64'])\n",
    "\n",
    "# changing datatype of a column\n",
    "df[col_name] = df[col_name].astype(dtype_name)\n",
    "\n",
    "# Downcasting column - eg from float64 to float16\n",
    "df[col] = pd.to_numeric(df[col], downcast='float') # if column is not float, first use astype to convert to float\n",
    "\n",
    "# Converting to datetime\n",
    "df[col] = pd.to_datetime(df[col])\n",
    "\n",
    "#Converting column to category datatype - similar to enumerated datatype in postgres\n",
    "df[col] = df[col].astype('category')\n",
    "\n",
    "# Null Values\n",
    "df.isnull().sum()\n",
    "\n",
    "# Reading CSV file\n",
    "eg = pd.read_csv('eg.csv',parse_dates=[cols],usecols=keep_cols,chunksize=100,dtype={col1:'type',col2:'type'})\n",
    "eg = pd.read_csv('eg.csv',nrows = 5) # read 5 rows only\n",
    "\n",
    "# Combining dataframes or chunks of dataframes\n",
    "pd.concat(list_of_dfs)\n",
    "\n",
    "# Groupby\n",
    "group = df.groupby(col)\n",
    "group.sum()\n",
    "\n",
    "# Augmenting with sqlite3\n",
    "df.to_sql('table_name',conn, index=False, if_exists= 'append')\n",
    "results_df = pd.read_sql(query,conn)\n",
    "\n",
    "# using %%timeit to time code\n",
    "%%timeit\n",
    "<code>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sqlite3 and Postgres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_runs(teams):\n",
    "    home_runs=[]\n",
    "    q = \"SELECT SUM(HR) FROM Batting WHERE teamID = ?;\"\n",
    "    for team in teams:\n",
    "        home_runs.append(cur.execute(q,[team]).fetchone()[0])\n",
    "    return home_runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "# Create an in memory database.\n",
    "memory = sqlite3.connect(':memory:')\n",
    "\n",
    "# Connect to our disk database.\n",
    "disk = sqlite3.connect('lahman2015.sqlite')\n",
    "\n",
    "# Create a query that will read the contents of the disk database into another database.\n",
    "dump = \"\".join(line for line in disk.iterdump())\n",
    "\n",
    "# Run the query to copy the database from disk into memory.\n",
    "memory.executescript(dump)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "# Seaborn Styling example\n",
    "sns.set_palette(\"GnBu_d\")\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "# Explore data\n",
    "sns.jointplot(x='column_x',y='column_y', data=DATAFRAME,kind='hex')\n",
    "sns.pairplot(DATAFRAME)\n",
    "# Seaborn Linear Model Plot\n",
    "sns.lmplot(x='column_x',y='column_y',data=DATAFRAME)\n",
    "\n",
    "# TRAINING the Data\n",
    "X = DATAFRAME[['column_x1','column_x2',...'column_xn']] # all the numerical variables used for training\n",
    "y = DATAFRAME['column_y'] # variable we are trying to predict\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lm = LinearRegression()\n",
    "lm.fit(X_train,y_train)\n",
    "print('Coefficients: \\n', lm.coef_)\n",
    "prediction = lm.predict(X_test)\n",
    "plt.scatter(y_test,prediction)\n",
    "plt.xlabel('Y Tested')\n",
    "plt.ylabel('Y Predicted')\n",
    "\n",
    "# EVALUATING the model\n",
    "from sklearn import metrics\n",
    "print('MAE: ',metrics.mean_absolute_error(y_test,prediction))\n",
    "print('MSE: ',metrics.mean_squared_error(y_test,prediction))\n",
    "print('RMSE: ',np.sqrt(metrics.mean_squared_error(y_test,prediction)))\n",
    "\n",
    "# Visualizing the RESIDUALS\n",
    "sns.distplot(y_test-prediction,bins=50)\n",
    "\n",
    "# Taking a look at coefficients\n",
    "pd.DataFrame(lm.coef_,X.columns,columns=['Coefficient'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing Missing Values\n",
    "sns.heatmap(DataFrame.isnull(),yticklabels=False,cbar=False,cmap='viridis')\n",
    "# Countplot\n",
    "sns.set_style('whitegrid')\n",
    "sns.countplot(x='Column1',hue='Column2',data=DataFrame,palette='RdBu_r')\n",
    "# Histogram\n",
    "sns.distplot(DataFrame['Column'].dropna(),kde=False,color='darkred',bins=30)\n",
    "DataFrame['Column'].hist(bins=30,color='darkred',alpha=0.7)\n",
    "# Using Cufflinks\n",
    "import cufflinks as cf\n",
    "cf.go_offline()\n",
    "DataFrame['Column'].iplot(kind='hist',bins=30,color='green')\n",
    "# Box Plot\n",
    "plt.figure(figsize=(12, 7))\n",
    "sns.boxplot(x='Pclass',y='Age',data=train,palette='winter')\n",
    "# Converting Categorical Features\n",
    "column1 = pd.get_dummies(DataFrame['column1'],drop_first=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Test Split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(DataFrame.drop('Column_y',axis=1), DataFrame['Column_y'], test_size=0.30, random_state=101)\n",
    "\n",
    "# Training and Predicting\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logmodel = LogisticRegression()\n",
    "logmodel.fit(X_train,y_train)\n",
    "predictions = logmodel.predict(X_test)\n",
    "\n",
    "# Model Evaluation\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test,predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
